#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é€šç”¨çš„å°çº¢ä¹¦ç¬”è®°è§£æå™¨
åŸºäºget_text()æ–¹æ³•å’Œç¬¦å·è¯†åˆ«ï¼Œé€‚ç”¨äºä»»ä½•å°çº¢ä¹¦ç¬”è®°
"""

import requests
from bs4 import BeautifulSoup
import re
from typing import Dict, List, Optional
import logging

class XiaohongshuNoteParser:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        
        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def parse_note(self, url: str) -> Optional[Dict]:
        """
        è§£æå°çº¢ä¹¦ç¬”è®°
        
        Args:
            url: å°çº¢ä¹¦ç¬”è®°é“¾æ¥
            
        Returns:
            è§£æåçš„ç¬”è®°æ•°æ®ï¼ŒåŒ…å«åœ°ç‚¹ã€æ ‡ç­¾ç­‰ä¿¡æ¯
        """
        try:
            self.logger.info(f"å¼€å§‹è§£æå°çº¢ä¹¦ç¬”è®°: {url}")
            
            # è·å–ç½‘é¡µå†…å®¹
            response = self.session.get(url, timeout=10, allow_redirects=True)
            response.raise_for_status()
            
            self.logger.info(f"è·å–ç½‘é¡µæˆåŠŸï¼ŒçŠ¶æ€ç : {response.status_code}")
            self.logger.info(f"æœ€ç»ˆURL: {response.url}")
            
            # è§£æHTML
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ä½¿ç”¨get_text()æ–¹æ³•æå–æ‰€æœ‰æ–‡æœ¬ï¼ˆä¸æµ‹è¯•è„šæœ¬ä¿æŒä¸€è‡´ï¼‰
            all_text = soup.get_text()
            self.logger.info(f"æå–çš„æ–‡æœ¬é•¿åº¦: {len(all_text)} å­—ç¬¦")
            
            # ä¿å­˜æå–çš„æ–‡æœ¬ç”¨äºè°ƒè¯•
            with open('debug_extracted_text.txt', 'w', encoding='utf-8') as f:
                f.write(all_text)
            self.logger.info("å·²ä¿å­˜æå–çš„æ–‡æœ¬åˆ° debug_extracted_text.txt")
            
            # æå–ç¬”è®°ä¿¡æ¯
            note_data = self._extract_note_data(all_text, url)
            
            if note_data:
                self.logger.info(f"æˆåŠŸè§£æç¬”è®°: {note_data.get('title', 'æœªçŸ¥æ ‡é¢˜')}")
                self.logger.info(f"æå–åˆ° {len(note_data.get('places', []))} ä¸ªPOI")
                return note_data
            else:
                self.logger.warning("æœªèƒ½æå–åˆ°æœ‰æ•ˆçš„ç¬”è®°æ•°æ®")
                return None
                
        except Exception as e:
            self.logger.error(f"è§£æå°çº¢ä¹¦ç¬”è®°å¤±è´¥: {str(e)}")
            return None
    
    def _extract_note_data(self, text: str, original_url: str) -> Optional[Dict]:
        """ä»æå–çš„æ–‡æœ¬ä¸­æå–ç¬”è®°æ•°æ®"""
        
        # æå–æ ‡é¢˜
        title = self._extract_title(text)
        
        # æå–æ­£æ–‡å†…å®¹
        content = self._extract_content(text)
        
        # æå–åœ°ç‚¹ä¿¡æ¯ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰
        places = self._extract_places_from_text(text)
        
        # æå–æ ‡ç­¾
        tags = self._extract_tags_from_text(text)
        
        # å¦‚æœæ²¡æœ‰æå–åˆ°åœ°ç‚¹ï¼Œè¿”å›None
        if not places:
            self.logger.warning("æœªèƒ½æå–åˆ°ä»»ä½•åœ°ç‚¹ä¿¡æ¯")
            return None
        
        return {
            'title': title or "æœªå‘½åè·¯çº¿",
            'content': content or "",
            'places': places,
            'tags': tags,
            'source_url': original_url,
            'parsed_at': self._get_current_timestamp()
        }
    
    def _extract_title(self, text: str) -> str:
        """æå–ç¬”è®°æ ‡é¢˜"""
        # æŸ¥æ‰¾å¯èƒ½çš„æ ‡é¢˜æ¨¡å¼
        title_patterns = [
            r'å°çº¢ä¹¦\s*\n\s*([^\n]+)',  # å°çº¢ä¹¦åé¢çš„ç¬¬ä¸€è¡Œ
            r'([^#\n]{5,30})',  # 5-30ä¸ªå­—ç¬¦çš„éæ ‡ç­¾æ–‡æœ¬
        ]
        
        for pattern in title_patterns:
            match = re.search(pattern, text)
            if match:
                title = match.group(1).strip()
                if title and len(title) > 3 and 'å°çº¢ä¹¦' not in title:
                    return title
        
        return ""
    
    def _extract_content(self, text: str) -> str:
        """æå–ç¬”è®°æ­£æ–‡å†…å®¹"""
        # æå–å‰å‡ æ®µæœ‰æ„ä¹‰çš„æ–‡æœ¬
        lines = text.split('\n')
        content_lines = []
        
        for line in lines:
            line = line.strip()
            if line and len(line) > 10 and not line.startswith('#'):
                content_lines.append(line)
                if len(content_lines) >= 5:  # æœ€å¤šå–5è¡Œ
                    break
        
        return '\n'.join(content_lines)
    
    def _extract_places_from_text(self, text: str) -> List[Dict]:
        """ä»æ–‡æœ¬ä¸­æå–åœ°ç‚¹ä¿¡æ¯ï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰"""
        places = []
        
        # æ–¹æ³•1ï¼šåŸºäºç¬¦å·è¯†åˆ«åœ°å€ï¼ˆå°çº¢ä¹¦ç¬”è®°çš„æ ‡å‡†æ–¹å¼ï¼‰
        symbol_places = self._extract_places_by_symbol(text)
        places.extend(symbol_places)
        
        # æ–¹æ³•2ï¼šåŸºäºåœ°å€æ ¼å¼è¯†åˆ«
        format_places = self._extract_places_by_format(text)
        places.extend(format_places)
        
        # æ–¹æ³•3ï¼šåŸºäºPOIå…³é”®è¯è¯†åˆ«
        keyword_places = self._extract_places_by_keywords(text)
        places.extend(keyword_places)
        
        # å»é‡å’Œåˆå¹¶
        unique_places = self._merge_and_deduplicate_places(places)
        
        self.logger.info(f"æå–åˆ° {len(unique_places)} ä¸ªå”¯ä¸€åœ°ç‚¹")
        return unique_places
    
    def _extract_places_by_symbol(self, text: str) -> List[Dict]:
        """åŸºäºç¬¦å·è¯†åˆ«åœ°å€"""
        places = []
        
        # æŸ¥æ‰¾ç¬¦å·åé¢çš„åœ°å€ä¿¡æ¯
        symbol_pattern = r'ğŸ“\s*([^ï¼Œã€‚\n]+)'
        matches = re.findall(symbol_pattern, text)
        
        for match in matches:
            address = match.strip()
            if self._is_valid_address(address):
                place_name = self._extract_place_name_from_address(address)
                places.append({
                    'name': place_name,
                    'address': address,
                    'coordinates': self._get_coordinates_from_address(address),
                    'category': self._categorize_place(place_name),
                    'source': 'symbol'
                })
        
        return places
    
    def _extract_places_by_format(self, text: str) -> List[Dict]:
        """åŸºäºåœ°å€æ ¼å¼è¯†åˆ«"""
        places = []
        
        # è¯†åˆ«å¸¸è§çš„åœ°å€æ ¼å¼
        address_patterns = [
            r'([^ï¼Œã€‚\n]*\d+[^ï¼Œã€‚\n]*[è·¯è¡—å··å·][^ï¼Œã€‚\n]*)',  # åŒ…å«è·¯ã€è¡—ã€å··ã€å·çš„åœ°å€
            r'([^ï¼Œã€‚\n]*[çœå¸‚åŒºå¿][^ï¼Œã€‚\n]*)',  # åŒ…å«çœå¸‚åŒºå¿çš„åœ°å€
            r'([^ï¼Œã€‚\n]*[A-Za-z]+\s*[A-Za-z]+[^ï¼Œã€‚\n]*)',  # è‹±æ–‡åœ°å€
        ]
        
        for pattern in address_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                address = match.strip()
                if self._is_valid_address(address) and len(address) > 5:
                    place_name = self._extract_place_name_from_address(address)
                    places.append({
                        'name': place_name,
                        'address': address,
                        'coordinates': self._get_coordinates_from_address(address),
                        'category': self._categorize_place(place_name),
                        'source': 'format'
                    })
        
        return places
    
    def _extract_places_by_keywords(self, text: str) -> List[Dict]:
        """åŸºäºPOIå…³é”®è¯è¯†åˆ«"""
        places = []
        
        # å®šä¹‰POIå…³é”®è¯æ¨¡å¼
        poi_patterns = [
            r'([^ï¼Œã€‚\n]*[ç«™][^ï¼Œã€‚\n]*)',  # è½¦ç«™ã€åœ°é“ç«™ç­‰
            r'([^ï¼Œã€‚\n]*[é¦†][^ï¼Œã€‚\n]*)',  # åšç‰©é¦†ã€å±•è§ˆé¦†ç­‰
            r'([^ï¼Œã€‚\n]*[è¡—][^ï¼Œã€‚\n]*)',  # å•†ä¸šè¡—ã€æ­¥è¡Œè¡—ç­‰
            r'([^ï¼Œã€‚\n]*[åº—][^ï¼Œã€‚\n]*)',  # é¤å…ã€å•†åº—ç­‰
            r'([^ï¼Œã€‚\n]*[ç¥ç¤¾][^ï¼Œã€‚\n]*)',  # ç¥ç¤¾ã€å¯ºåº™ç­‰
            r'([^ï¼Œã€‚\n]*[å…¬å›­][^ï¼Œã€‚\n]*)',  # å…¬å›­ã€å¹¿åœºç­‰
        ]
        
        for pattern in poi_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                place_name = match.strip()
                # æ¸…ç†POIåç§°ï¼Œç§»é™¤å›¾ç‰‡ç¼–å·ç­‰æ— å…³ä¿¡æ¯
                cleaned_name = self._clean_place_name(place_name)
                if cleaned_name and self._is_valid_place_name(cleaned_name):
                    places.append({
                        'name': cleaned_name,
                        'address': cleaned_name,  # æš‚æ—¶ç”¨åç§°ä½œä¸ºåœ°å€
                        'coordinates': self._get_coordinates_from_address(cleaned_name),
                        'category': self._categorize_place(cleaned_name),
                        'source': 'keyword'
                    })
        
        return places
    
    def _is_valid_address(self, address: str) -> bool:
        """éªŒè¯åœ°å€æ˜¯å¦æœ‰æ•ˆ"""
        if not address or len(address) < 5:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«åœ°å€ç‰¹å¾
        address_features = ['è·¯', 'è¡—', 'å··', 'å·', 'çœ', 'å¸‚', 'åŒº', 'å¿', 'Chome', 'Street', 'Road']
        return any(feature in address for feature in address_features)
    
    def _is_valid_place_name(self, name: str) -> str:
        """éªŒè¯åœ°ç‚¹åç§°æ˜¯å¦æœ‰æ•ˆ"""
        if not name or len(name) < 2:
            return False
        
        # è¿‡æ»¤æ‰ä¸€äº›æ˜æ˜¾ä¸æ˜¯åœ°ç‚¹çš„å†…å®¹
        invalid_patterns = [
            r'^[0-9\s\-_]+$',  # çº¯æ•°å­—å’Œç¬¦å·
            r'^[pP]\d+',  # å›¾ç‰‡ç¼–å·
            r'åº—ä¸»', 'å¤§å”', 'å°æœ‹å‹',  # äººç‰©æè¿°
            r'å¥½åƒ', 'å¯çˆ±', 'äº²åˆ‡',  # æè¿°æ€§è¯æ±‡
        ]
        
        for pattern in invalid_patterns:
            if re.match(pattern, name):
                return False
        
        return True
    
    def _clean_place_name(self, place_name: str) -> str:
        """æ¸…ç†POIåç§°ï¼Œç§»é™¤å›¾ç‰‡ç¼–å·ç­‰æ— å…³ä¿¡æ¯"""
        if not place_name:
            return ""
        
        # ç§»é™¤å›¾ç‰‡ç¼–å·ï¼ˆå¦‚ p12ã€P1 ç­‰ï¼‰
        cleaned = re.sub(r'^[pP]\d+[^a-zA-Z\u4e00-\u9fff]*', '', place_name)
        
        # ç§»é™¤ä¸€äº›æ— å…³è¯æ±‡
        cleaned = re.sub(r'æ˜¯ä¸€å®¶å«\s*', '', cleaned)
        cleaned = re.sub(r'çš„\s*', '', cleaned)
        cleaned = re.sub(r'å¥½åƒï¼?', '', cleaned)
        cleaned = re.sub(r'å¯ä»¥é€›é€›æ‰“å‘æ—¶é—´', '', cleaned)
        cleaned = re.sub(r'è¿›å»äº†å°±å‡ºä¸æ¥äº†', '', cleaned)
        cleaned = re.sub(r'å¤ªå¯çˆ±äº†ï¼?', '', cleaned)
        cleaned = re.sub(r'åº—ä¸»å¤§å”äººè¶…çº§äº²åˆ‡', '', cleaned)
        cleaned = re.sub(r'è¿˜é€äº†æˆ‘ä»¬é¢åŒ…è¶…äººçš„å°é›¶é£Ÿ', '', cleaned)
        cleaned = re.sub(r'åˆé¤æ¨è', '', cleaned)
        cleaned = re.sub(r'æ˜¯æœ‰åçš„', '', cleaned)
        cleaned = re.sub(r'è¿˜è›®å°çš„', '', cleaned)
        cleaned = re.sub(r'è·ç¦»å•†ä¸šè¡—è¦èµ°ä¸€æ®µè·¯', '', cleaned)
        cleaned = re.sub(r'ä»ç¥ç¤¾ä¸€è·¯èµ°å›æ—¥æš®é‡Œç«™', '', cleaned)
        cleaned = re.sub(r'é€”ç»å®‰é™çš„ä½å®…åŒº', '', cleaned)
        cleaned = re.sub(r'é€”ä¸­è¿˜é‡åˆ°äº†å°æœ‹å‹ä»¬æ”¾å­¦', '', cleaned)
        
        # æ¸…ç†å¤šä½™çš„ç©ºæ ¼å’Œæ ‡ç‚¹
        cleaned = re.sub(r'\s+', ' ', cleaned)
        cleaned = cleaned.strip(' ã€€ï¼Œã€‚ï¼ï¼Ÿã€')
        
        return cleaned

    def _extract_place_name_from_address(self, address: str) -> str:
        """ä»åœ°å€ä¸­æå–åœ°ç‚¹åç§°"""
        # ç®€å•çš„åç§°æå–é€»è¾‘
        name = address.strip()
        
        # ç§»é™¤ä¸€äº›æ— å…³å­—ç¬¦
        name = re.sub(r'[ğŸ“ğŸš‰â›©ï¸ğŸ”]', '', name)
        name = re.sub(r'åœ°å€[ï¼š:]', '', name)
        name = re.sub(r'ä½ç½®[ï¼š:]', '', name)
        
        # å¦‚æœåœ°å€å¾ˆé•¿ï¼Œå°è¯•æå–å‰é¢çš„éƒ¨åˆ†ä½œä¸ºåç§°
        if len(name) > 20:
            # å°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœ‰æ„ä¹‰çš„åˆ†éš”ç¬¦
            separators = ['ï¼Œ', 'ã€', ' ', ',', '-']
            for sep in separators:
                if sep in name:
                    name = name.split(sep)[0]
                    break
        
        return name.strip()
    
    def _categorize_place(self, place_name: str) -> str:
        """å¯¹åœ°ç‚¹è¿›è¡Œåˆ†ç±»"""
        if not place_name:
            return 'other'
        
        # åŸºäºå…³é”®è¯è¿›è¡Œåˆ†ç±»
        if any(keyword in place_name for keyword in ['ç«™', 'Station']):
            return 'transportation'
        elif any(keyword in place_name for keyword in ['é¦†', 'Museum', 'Gallery']):
            return 'attraction'
        elif any(keyword in place_name for keyword in ['è¡—', 'Street', 'Mall']):
            return 'shopping'
        elif any(keyword in place_name for keyword in ['åº—', 'Restaurant', 'Shop']):
            return 'restaurant'
        elif any(keyword in place_name for keyword in ['ç¥ç¤¾', 'Temple', 'Shrine']):
            return 'attraction'
        elif any(keyword in place_name for keyword in ['å…¬å›­', 'Park', 'Square']):
            return 'park'
        else:
            return 'other'
    
    def _get_coordinates_from_address(self, address: str) -> Dict[str, float]:
        """ä»åœ°å€è·å–åæ ‡ï¼ˆå®é™…é¡¹ç›®ä¸­åº”è¯¥è°ƒç”¨åœ°ç†ç¼–ç APIï¼‰"""
        # è¿™é‡Œè¿”å›é»˜è®¤åæ ‡ï¼Œå®é™…é¡¹ç›®ä¸­åº”è¯¥ï¼š
        # 1. è°ƒç”¨Google Geocoding API
        # 2. æˆ–è€…è°ƒç”¨å…¶ä»–åœ°ç†ç¼–ç æœåŠ¡
        # 3. æ ¹æ®åœ°å€è¿”å›å‡†ç¡®çš„åæ ‡
        
        # ä¸´æ—¶è¿”å›é»˜è®¤åæ ‡ï¼ˆä¸œäº¬å¸‚ä¸­å¿ƒï¼‰
        return {'lat': 35.6762, 'lng': 139.6503}
    
    def _merge_and_deduplicate_places(self, places: List[Dict]) -> List[Dict]:
        """åˆå¹¶å’Œå»é‡åœ°ç‚¹"""
        unique_places = []
        seen_names = set()
        
        for place in places:
            name = place.get('name', '').strip()
            if name and name not in seen_names:
                unique_places.append(place)
                seen_names.add(name)
        
        # æŒ‰æ¥æºä¼˜å…ˆçº§æ’åºï¼šsymbol > format > keyword
        source_priority = {'symbol': 3, 'format': 2, 'keyword': 1}
        unique_places.sort(key=lambda x: source_priority.get(x.get('source', 0), 0), reverse=True)
        
        return unique_places
    
    def _extract_tags_from_text(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–æ ‡ç­¾"""
        tags = []
        
        # æŸ¥æ‰¾æ ‡ç­¾æ¨¡å¼
        tag_pattern = r'#([^#\s]+)'
        matches = re.findall(tag_pattern, text)
        
        # è¿‡æ»¤å’Œæ¸…ç†æ ‡ç­¾
        for tag in matches:
            tag = tag.strip()
            if tag and len(tag) > 1 and tag not in tags:
                tags.append(tag)
        
        return tags[:15]  # æœ€å¤šè¿”å›15ä¸ªæ ‡ç­¾
    
    def _get_current_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().isoformat()
